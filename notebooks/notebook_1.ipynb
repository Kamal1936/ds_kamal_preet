{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "CANDIDATE = \"kamal_preet\"\n",
        "ROOT = f\"ds_{CANDIDATE}\"\n",
        "CSV_DIR = os.path.join(ROOT, \"csv_files\")\n",
        "OUT_DIR = os.path.join(ROOT, \"outputs\")\n",
        "NB_DIR = os.path.join(ROOT, \"notebooks\")\n",
        "for p in [ROOT, CSV_DIR, OUT_DIR, NB_DIR]: os.makedirs(p, exist_ok=True)\n",
        "print(\"Created:\", ROOT)"
      ],
      "metadata": {
        "id": "2cY_Z4Jtvm2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b98608-bff7-4c95-d473-0fd49e43e3c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: ds_kamal_preet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_lmqQx7rFPp",
        "outputId": "866db022-e731-4cfc-836f-5938e35d5676"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6vauEw-trths",
        "outputId": "25282af0-a88c-410f-aed0-b40076940652"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ffee38d9-378d-4d6e-bea3-d5f8ca6cb6d8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ffee38d9-378d-4d6e-bea3-d5f8ca6cb6d8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving historical_data.csv to historical_data (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kkOzIGDxrzr0",
        "outputId": "f3b2b409-0f4a-4570-dea6-93d8f827a9ce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-682e002e-f0b7-4aed-9023-89b0bfb1e935\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-682e002e-f0b7-4aed-9023-89b0bfb1e935\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fear_greed_index.csv to fear_greed_index (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install reportlab scipy"
      ],
      "metadata": {
        "id": "FYCZi1U5tBB6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "hist_path = \"historical_data.csv\"\n",
        "fg_path   = \"fear_greed_index.csv\"\n",
        "\n",
        "hist = pd.read_csv(hist_path, low_memory=False)\n",
        "fg   = pd.read_csv(fg_path, low_memory=False)\n",
        "\n",
        "print(\"Historical rows,cols:\", hist.shape)\n",
        "print(hist.head(3))\n",
        "print(\"\\nFearGreed rows,cols:\", fg.shape)\n",
        "print(fg.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUvXcQsStdMY",
        "outputId": "e4f599c6-a941-4d77-ad71-9b1862e4d2f1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Historical rows,cols: (211224, 16)\n",
            "                                      Account  Coin  Execution Price  \\\n",
            "0  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9769   \n",
            "1  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9800   \n",
            "2  0xae5eacaf9c6b9111fd53034a602c192a04e082ed  @107           7.9855   \n",
            "\n",
            "   Size Tokens  Size USD Side     Timestamp IST  Start Position Direction  \\\n",
            "0       986.87   7872.16  BUY  02-12-2024 22:50        0.000000       Buy   \n",
            "1        16.00    127.68  BUY  02-12-2024 22:50      986.524596       Buy   \n",
            "2       144.09   1150.63  BUY  02-12-2024 22:50     1002.518996       Buy   \n",
            "\n",
            "   Closed PnL                                   Transaction Hash     Order ID  \\\n",
            "0         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
            "1         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
            "2         0.0  0xec09451986a1874e3a980418412fcd0201f500c95bac...  52017706630   \n",
            "\n",
            "   Crossed       Fee      Trade ID     Timestamp  \n",
            "0     True  0.345404  8.950000e+14  1.730000e+12  \n",
            "1     True  0.005600  4.430000e+14  1.730000e+12  \n",
            "2     True  0.050431  6.600000e+14  1.730000e+12  \n",
            "\n",
            "FearGreed rows,cols: (2644, 4)\n",
            "    timestamp  value classification        date\n",
            "0  1517463000     30           Fear  2018-02-01\n",
            "1  1517549400     15   Extreme Fear  2018-02-02\n",
            "2  1517635800     40           Fear  2018-02-03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardize column names\n",
        "def to_snake(s):\n",
        "    return s.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"/\", \"_\")\n",
        "\n",
        "hist.columns = [to_snake(c) for c in hist.columns]\n",
        "fg.columns   = [to_snake(c) for c in fg.columns]\n"
      ],
      "metadata": {
        "id": "00JCMl8HvFWr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse timestamps\n",
        "import pytz\n",
        "IST = pytz.timezone(\"Asia/Kolkata\")\n",
        "\n",
        "# Historical data: prefer 'timestamp' epoch ms; fallback to 'timestamp_ist' string\n",
        "if \"timestamp\" in hist.columns:\n",
        "    hist[\"timestamp_ms\"] = pd.to_numeric(hist[\"timestamp\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    hist[\"ts_utc\"] = pd.to_datetime(hist[\"timestamp_ms\"], unit=\"ms\", utc=True, errors=\"coerce\")\n",
        "    hist[\"ts_ist\"] = hist[\"ts_utc\"].dt.tz_convert(IST)\n",
        "    hist[\"date_ist\"] = hist[\"ts_ist\"].dt.date\n",
        "elif \"timestamp_ist\" in hist.columns:\n",
        "    hist[\"ts_ist\"] = pd.to_datetime(hist[\"timestamp_ist\"], format=\"%d-%m-%Y %H:%M\", errors=\"coerce\").dt.tz_localize(IST)\n",
        "    hist[\"ts_utc\"] = hist[\"ts_ist\"].dt.tz_convert(\"UTC\")\n",
        "    hist[\"date_ist\"] = hist[\"ts_ist\"].dt.date\n",
        "else:\n",
        "    raise Exception(\"No timestamp found in historical file\")\n",
        "\n",
        "# Fear & Greed: prefer 'date' column, else convert epoch seconds\n",
        "if \"date\" in fg.columns and fg[\"date\"].notna().any():\n",
        "    fg[\"date_ist\"] = pd.to_datetime(fg[\"date\"], errors=\"coerce\").dt.date\n",
        "elif \"timestamp\" in fg.columns:\n",
        "    fg[\"_ts\"] = pd.to_numeric(fg[\"timestamp\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    fg[\"_utc\"] = pd.to_datetime(fg[\"_ts\"], unit=\"s\", utc=True, errors=\"coerce\")\n",
        "    fg[\"date_ist\"] = fg[\"_utc\"].dt.tz_convert(IST).dt.date\n",
        "else:\n",
        "    raise Exception(\"No date/timestamp found in fear greed file\")"
      ],
      "metadata": {
        "id": "XF_VrkImvQUC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean essential fields (drop rows missing critical info)\n",
        "essential = [c for c in [\"account\",\"coin\",\"ts_utc\",\"size_usd\",\"execution_price\"] if c in hist.columns]\n",
        "hist = hist.dropna(subset=essential)\n",
        "hist = hist.drop_duplicates()\n",
        "print(\"After cleaning:\", hist.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhxZHgWkwK2u",
        "outputId": "081fa573-bdbc-4871-a916-6b66f5864b88"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After cleaning: (211224, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize text fields\n",
        "def normalize_side(s):\n",
        "    if pd.isna(s): return np.nan\n",
        "    s = str(s).strip().upper()\n",
        "    if s in {\"B\",\"BUY\",\"LONG\"}: return \"BUY\"\n",
        "    if s in {\"S\",\"SELL\",\"SHORT\"}: return \"SELL\"\n",
        "    return s\n",
        "\n",
        "if \"side\" in hist.columns:\n",
        "    hist[\"side\"] = hist[\"side\"].apply(normalize_side)"
      ],
      "metadata": {
        "id": "_eFQ0hWhwRni"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save cleaned CSVs\n",
        "hist.to_csv(os.path.join(CSV_DIR, \"historical_data_clean.csv\"), index=False)\n",
        "fg.to_csv(os.path.join(CSV_DIR, \"fear_greed_index_clean.csv\"), index=False)"
      ],
      "metadata": {
        "id": "D-o7tf3_wzaV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge trade data with sentiment by date\n",
        "# Normalize FG classification (map extreme variants into Fear/Greed)\n",
        "hist[\"date_ist\"] = pd.to_datetime(hist[\"date_ist\"], errors=\"coerce\").dt.date\n",
        "fg[\"date_ist\"]   = pd.to_datetime(fg[\"date_ist\"], errors=\"coerce\").dt.date\n",
        "\n",
        "# 2. Normalize sentiment classification\n",
        "fg[\"classification_norm\"] = fg[\"classification\"].astype(str).str.strip().str.lower()\n",
        "fg_map = {\n",
        "    \"extreme fear\": \"Fear\",\n",
        "    \"fear\": \"Fear\",\n",
        "    \"neutral\": \"Neutral\",\n",
        "    \"greed\": \"Greed\",\n",
        "    \"extreme greed\": \"Greed\"\n",
        "}\n",
        "fg[\"fg_class\"] = fg[\"classification_norm\"].map(fg_map).fillna(\"Neutral\")\n",
        "\n",
        "# 3. Prepare Fear & Greed subset for merge\n",
        "fg_join = fg[[\"date_ist\", \"value\", \"fg_class\"]].rename(columns={\"value\": \"fg_value\"})\n",
        "\n",
        "# 4. Merge with historical trades\n",
        "merged = hist.merge(fg_join, on=\"date_ist\", how=\"left\")\n",
        "\n",
        "# 5. Save merged file\n",
        "merged.to_csv(os.path.join(CSV_DIR, \"trades_with_sentiment.csv\"), index=False)\n",
        "\n",
        "# 6. Quick sanity check\n",
        "print(\"Merged rows:\", merged.shape)\n",
        "print(\"Sentiment counts:\\n\", merged[\"fg_class\"].value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8xQG9NAw949",
        "outputId": "b00d7760-9117-4ab2-fb14-dd1588fb5155"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged rows: (211224, 22)\n",
            "Sentiment counts:\n",
            " fg_class\n",
            "Neutral    141012\n",
            "Greed       43251\n",
            "NaN         26961\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Make sure merged has fg_class\n",
        "if \"fg_class\" not in merged.columns:\n",
        "    raise ValueError(\"fg_class not found in merged dataset. Re-run merge cell first.\")\n",
        "\n",
        "# Group by sentiment\n",
        "by_sent = merged.groupby(\"fg_class\").agg(\n",
        "    trades=(\"account\", \"count\"),\n",
        "    usd_volume=(\"size_usd\", \"sum\"),\n",
        "    win_rate=(\"closed_pnl\", lambda s: (s > 0).mean() if s.notna().any() else np.nan),\n",
        "    median_pnl=(\"closed_pnl\", \"median\")\n",
        ").reset_index()\n",
        "\n",
        "print(\"Sentiment summary:\\n\", by_sent)\n",
        "\n",
        "# ---- Chart 1: Win Rate by Sentiment ----\n",
        "plt.figure()\n",
        "plt.bar(by_sent[\"fg_class\"], by_sent[\"win_rate\"])\n",
        "plt.title(\"Win Rate by Sentiment\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Win Rate\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, \"winrate_by_sentiment.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ---- Chart 2: USD Volume by Sentiment ----\n",
        "plt.figure()\n",
        "plt.bar(by_sent[\"fg_class\"], by_sent[\"usd_volume\"])\n",
        "plt.title(\"USD Volume by Sentiment\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"USD Volume\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, \"volume_by_sentiment.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved sentiment charts in:\", OUT_DIR)\n",
        "print(os.listdir(OUT_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5EC0aiyXCgd",
        "outputId": "d2264839-65da-4feb-ef4e-7213d065a4be"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment summary:\n",
            "   fg_class  trades    usd_volume  win_rate  median_pnl\n",
            "0    Greed   43251  1.549104e+08  0.453492         0.0\n",
            "1  Neutral  141012  7.260017e+08  0.410185         0.0\n",
            "Saved sentiment charts in: ds_kamal_preet/outputs\n",
            "['daily_usd_volume.png', 'winrate_by_sentiment.png', 'daily_trades_count.png', 'pnl_distribution.png', 'volume_by_sentiment.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Coverage\n",
        "print(\"Time range:\", merged[\"ts_utc\"].min(), \"→\", merged[\"ts_utc\"].max())\n",
        "\n",
        "# 2. Daily summary\n",
        "merged[\"date_ist\"] = pd.to_datetime(merged[\"date_ist\"])\n",
        "daily = merged.groupby(\"date_ist\").agg(\n",
        "    trades=(\"account\",\"count\"),\n",
        "    usd_volume=(\"size_usd\",\"sum\"),\n",
        "    median_trade_usd=(\"size_usd\",\"median\")\n",
        ").reset_index()\n",
        "daily.to_csv(os.path.join(CSV_DIR,\"daily_activity_summary.csv\"), index=False)\n",
        "\n",
        "# 3. Per coin\n",
        "coin = merged.groupby(\"coin\").agg(\n",
        "    trades=(\"account\",\"count\"),\n",
        "    usd_volume=(\"size_usd\",\"sum\")\n",
        ").reset_index().sort_values(\"usd_volume\", ascending=False)\n",
        "coin.head(10).to_csv(os.path.join(CSV_DIR,\"top_coins_by_volume.csv\"), index=False)\n",
        "\n",
        "# 4. Profitability\n",
        "if \"closed_pnl\" in merged.columns:\n",
        "    merged[\"closed_pnl\"] = pd.to_numeric(merged[\"closed_pnl\"], errors=\"coerce\")\n",
        "    win_rate = (merged[\"closed_pnl\"] > 0).mean()\n",
        "    median_pnl = merged[\"closed_pnl\"].median()\n",
        "    print(\"Win rate:\", win_rate, \"Median PnL:\", median_pnl)\n",
        "\n",
        "# 5. Sentiment summary\n",
        "sent = merged.groupby(\"fg_class\").agg(\n",
        "    trades=(\"account\",\"count\"),\n",
        "    usd_volume=(\"size_usd\",\"sum\"),\n",
        "    win_rate=(\"closed_pnl\", lambda s: (s>0).mean() if s.notna().any() else np.nan),\n",
        "    median_pnl=(\"closed_pnl\",\"median\")\n",
        ").reset_index()\n",
        "sent.to_csv(os.path.join(CSV_DIR,\"sentiment_summary.csv\"), index=False)\n",
        "print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAsl-RmdxIQb",
        "outputId": "b2bd4d1d-03eb-41c3-86c0-6c17e14b8363"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time range: 2023-03-28 10:40:00+00:00 → 2025-06-15 15:06:40+00:00\n",
            "Win rate: 0.4112648183918494 Median PnL: 0.0\n",
            "  fg_class  trades    usd_volume  win_rate  median_pnl\n",
            "0    Greed   43251  1.549104e+08  0.453492         0.0\n",
            "1  Neutral  141012  7.260017e+08  0.410185         0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(); plt.plot(daily[\"date_ist\"], daily[\"trades\"]); plt.title(\"Daily Trades\"); plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR,\"daily_trades_count.png\"), dpi=150); plt.close()\n",
        "\n",
        "plt.figure(); plt.plot(daily[\"date_ist\"], daily[\"usd_volume\"]); plt.title(\"Daily USD Volume\"); plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR,\"daily_usd_volume.png\"), dpi=150); plt.close()\n",
        "\n",
        "plt.figure(); plt.hist(merged[\"closed_pnl\"].dropna(), bins=50); plt.title(\"PnL Distribution\"); plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR,\"pnl_distribution.png\"), dpi=150); plt.close()\n"
      ],
      "metadata": {
        "id": "KwxH4FnaBvA0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic statistical check\n",
        "from scipy import stats\n",
        "fear_pnl = merged.loc[merged[\"fg_class\"]==\"Fear\", \"closed_pnl\"].dropna()\n",
        "greed_pnl = merged.loc[merged[\"fg_class\"]==\"Greed\", \"closed_pnl\"].dropna()\n",
        "if len(fear_pnl)>10 and len(greed_pnl)>10:\n",
        "    u, p = stats.mannwhitneyu(fear_pnl, greed_pnl, alternative=\"two-sided\")\n",
        "    print(\"Mann-Whitney U p-value:\", p)"
      ],
      "metadata": {
        "id": "FC-aJx-tCLnR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a short PDF report\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.utils import ImageReader\n",
        "\n",
        "REPORT_PATH = os.path.join(ROOT, \"ds_report.pdf\")\n",
        "c = canvas.Canvas(REPORT_PATH, pagesize=A4)\n",
        "c.setFont(\"Helvetica-Bold\", 14)\n",
        "c.drawString(40, 800, f\"Data Science Assessment — {CANDIDATE}\")\n",
        "c.setFont(\"Helvetica\", 10)\n",
        "y = 770\n",
        "c.drawString(40, y, f\"Rows (cleaned): {len(merged):,}\")\n",
        "y -= 15\n",
        "c.drawString(40, y, f\"Time range: {merged['ts_utc'].min()} -> {merged['ts_utc'].max()}\")\n",
        "y -= 25\n",
        "# Insert one image example\n",
        "img_path = os.path.join(OUT_DIR, \"daily_usd_volume.png\")\n",
        "if os.path.exists(img_path):\n",
        "    img = ImageReader(img_path)\n",
        "    c.drawImage(img, 40, 420, width=500, height=300)\n",
        "c.save()\n",
        "print(\"Saved report:\", REPORT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSjwA_-0Ch_u",
        "outputId": "489ad582-b546-445d-c5a8-e896e8fd2f98"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved report: ds_kamal_preet/ds_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CANDIDATE = \"kamal_preet\"   # <-- put your name here (use lowercase, underscores)\n",
        "COLAB_LINK = \"https://colab.research.google.com/drive/your-notebook-link\"  # <-- paste your Colab share link\n",
        "\n",
        "ROOT = f\"ds_{CANDIDATE}\"\n",
        "os.makedirs(ROOT, exist_ok=True)\n",
        "\n",
        "readme_text = f\"\"\"\n",
        "# ds_{CANDIDATE}\n",
        "\n",
        "## Project\n",
        "**Title:** Web3 Trading — Sentiment Alignment Analysis\n",
        "**Candidate:** {CANDIDATE}\n",
        "\n",
        "## Objective\n",
        "Analyze trader behaviour (trade volume, profitability) and align it with the Fear & Greed index. Produce cleaned datasets, EDA charts, and a concise PDF report.\n",
        "\n",
        "## Repository structure\n",
        "- csv_files/: cleaned CSVs and summaries\n",
        "- outputs/: PNG charts from EDA and sentiment\n",
        "- notebooks/: Colab notebook used for analysis\n",
        "- ds_report.pdf: short report with findings\n",
        "- README.md\n",
        "\n",
        "## How to run (Google Colab)\n",
        "1. Open the notebook: {COLAB_LINK}\n",
        "2. Upload `historical_data.csv` and `fear_greed_index.csv` when prompted.\n",
        "3. Run **Runtime → Restart and run all**.\n",
        "4. Results will be saved in `csv_files/`, `outputs/`, and `ds_report.pdf`.\n",
        "\n",
        "## Key files\n",
        "- historical_data_clean.csv\n",
        "- fear_greed_index_clean.csv\n",
        "- trades_with_sentiment.csv\n",
        "- daily_activity_summary.csv\n",
        "- sentiment_summary.csv\n",
        "- winrate_by_sentiment.png\n",
        "- volume_by_sentiment.png\n",
        "- ds_report.pdf\n",
        "\n",
        "## Key findings (fill in)\n",
        "- Win rate by sentiment: [ADD YOUR RESULT]\n",
        "- Median PnL overall: [ADD YOUR RESULT]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(ROOT, \"README.md\"), \"w\") as f:\n",
        "    f.write(readme_text.strip())\n",
        "\n",
        "print(\"README.md created at:\", os.path.join(ROOT, \"README.md\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg6WSZl4ZNC_",
        "outputId": "f3fbcf15-a549-4f71-abc7-ddf0234d37b1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md created at: ds_kamal_preet/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your name\n",
        "CANDIDATE = \"kamal_preet\"\n",
        "\n",
        "# 1. Zip the entire folder\n",
        "!zip -r ds_{CANDIDATE}.zip ds_{CANDIDATE}\n",
        "\n",
        "# 2. Download the zip file to your computer\n",
        "from google.colab import files\n",
        "files.download(f\"ds_{CANDIDATE}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Tfatm5hwFpsG",
        "outputId": "1c61170c-d60a-4e43-9ae5-e4d3649a86d2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: ds_kamal_preet/ (stored 0%)\n",
            "updating: ds_kamal_preet/outputs/ (stored 0%)\n",
            "updating: ds_kamal_preet/outputs/daily_usd_volume.png (deflated 12%)\n",
            "updating: ds_kamal_preet/outputs/daily_trades_count.png (deflated 14%)\n",
            "updating: ds_kamal_preet/outputs/pnl_distribution.png (deflated 32%)\n",
            "updating: ds_kamal_preet/notebooks/ (stored 0%)\n",
            "updating: ds_kamal_preet/csv_files/ (stored 0%)\n",
            "updating: ds_kamal_preet/csv_files/sentiment_summary.csv (deflated 17%)\n",
            "updating: ds_kamal_preet/csv_files/fear_greed_index_clean.csv (deflated 77%)\n",
            "updating: ds_kamal_preet/csv_files/daily_activity_summary.csv (deflated 38%)\n",
            "updating: ds_kamal_preet/csv_files/top_coins_by_volume.csv (deflated 22%)\n",
            "updating: ds_kamal_preet/csv_files/trades_with_sentiment.csv (deflated 86%)\n",
            "updating: ds_kamal_preet/csv_files/historical_data_clean.csv (deflated 86%)\n",
            "updating: ds_kamal_preet/ds_report.pdf (deflated 23%)\n",
            "updating: ds_kamal_preet/outputs/winrate_by_sentiment.png (deflated 26%)\n",
            "updating: ds_kamal_preet/outputs/volume_by_sentiment.png (deflated 24%)\n",
            "  adding: ds_kamal_preet/README.md (deflated 46%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_79cbd8cf-1643-4e31-986b-0066b4bb571b\", \"ds_kamal_preet.zip\", 19723650)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-4QauBVUNKwZ"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}